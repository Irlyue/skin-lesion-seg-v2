{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "if tf.__version__ != '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.0!')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/wenfeng/all-files/skin-lesion-seg-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import crf\n",
    "import inputs\n",
    "import my_utils\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = my_utils.load_config(os.path.join(BASE_DIR, 'config.json'))\n",
    "image_config = my_utils.load_config(os.path.join(BASE_DIR, 'image_config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RestoredModel:\n",
    "    def __init__(self, ckpt_file):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default() as g:\n",
    "            with tf.device('/cpu'):\n",
    "                od_graph_def = tf.GraphDef()\n",
    "                with tf.gfile.GFile(ckpt_file, 'rb') as fid:\n",
    "                    sg = fid.read()\n",
    "                    od_graph_def.ParseFromString(sg)\n",
    "                    tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "                self.image_ph = g.get_tensor_by_name('image_tensor:0')\n",
    "                self.bboxes = g.get_tensor_by_name('detection_boxes:0')\n",
    "                self.scores = g.get_tensor_by_name('detection_scores:0')\n",
    "                self.n_bboxes = g.get_tensor_by_name('num_detections:0')\n",
    "    \n",
    "    def inference_box(self, image):\n",
    "        sess = tf.get_default_session()\n",
    "        image = image[None] if len(image.shape) == 3 else image\n",
    "        return sess.run(self.bboxes, feed_dict={self.image_ph: image})[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = os.path.join(BASE_DIR, 'training/output_inference_graph.pb/frozen_inference_graph.pb')\n",
    "mm = RestoredModel(PATH_TO_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dermquest_listing = inputs.get_image_list(config['data_dir'], 'dermquest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dermquest_listing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dermquest_listing[0] + dermquest_listing[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(image_config['n_folds'], shuffle=True, random_state=image_config['split_seed'])\n",
    "\n",
    "train_idxes, test_idxes = list(kf.split(data))[image_config['k']]\n",
    "train_data = [data[idx] for idx in train_idxes]\n",
    "test_data = [data[idx] for idx in test_idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bbox_xy_to_tlwh(x, size):\n",
    "    \"\"\"\n",
    "    Change bounding-box prediction(ymin, xmin, ymax, xmax) back to its size. e.g.(0.1, 0.1, 0.8, 0.8)\n",
    "    \n",
    "    Return:\n",
    "        result: tuple, four integers giving(top, left, height, width)\n",
    "    \"\"\"\n",
    "    h, w = size\n",
    "    ymin, xmin, ymax, xmax = x\n",
    "    top = int(ymin * h)\n",
    "    left = int(xmin * w)\n",
    "    height = int((ymax - ymin) * h)\n",
    "    width = int((xmax - xmin) * w)\n",
    "    return top, left, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = test_data[20]\n",
    "with mm.graph.as_default() as g:\n",
    "    with tf.Session(graph=g, config=tf.ConfigProto(device_count={'GPU': 0})):\n",
    "        image = imread(path_base + '_orig.jpg')\n",
    "        label = imread(path_base + '_contour.png')\n",
    "        label[label == 255] = 1\n",
    "        bbox_gt = my_utils.calc_bbox(label)\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(211)\n",
    "        bbox_pred = mm.inference_box(image)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        top, left, height, width = bbox_xy_to_tlwh(bbox_pred, image.shape[:2])\n",
    "        plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='b'))\n",
    "        \n",
    "        top, left, height, width = bbox_gt\n",
    "        plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='r'))\n",
    "        \n",
    "        \n",
    "        plt.subplot(212)\n",
    "        label[label == 0] = 255\n",
    "        top, left, height, width = bbox_xy_to_tlwh(bbox_pred, image.shape[:2])\n",
    "        plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='b'))\n",
    "\n",
    "        top, left, height, width = bbox_gt\n",
    "        plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='r'))\n",
    "        \n",
    "        plt.imshow(label, cmap='gray')\n",
    "        \n",
    "        plt.show()\n",
    "        print(my_utils.calc_bbox_iou(bbox_gt, bbox_xy_to_tlwh(bbox_pred, image.shape[:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = test_data[1]\n",
    "with mm.graph.as_default() as g:\n",
    "    with tf.Session(graph=g, config=tf.ConfigProto(device_count={'GPU': 0})):\n",
    "        for i, base in enumerate(test_data):\n",
    "            image, label, bbox_gt = load_one_example(base, size=(600, 400))\n",
    "\n",
    "            bbox_pred = mm.inference_box(image)\n",
    "            iou_i = my_utils.calc_bbox_iou(bbox_gt, bbox_xy_to_tlwh(bbox_pred, image.shape[:2]))\n",
    "#             if iou_i < 0.6:\n",
    "#                 print(i, iou_i, '----------->')\n",
    "#             else:\n",
    "#                 print(i, iou_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mm.graph.as_default() as g:\n",
    "    result = {\n",
    "        'TP': 0,\n",
    "        'TN': 0,\n",
    "        'FP': 0,\n",
    "        'FN': 0\n",
    "    }\n",
    "    def update_dict(target, to_update):\n",
    "        for key in to_update:\n",
    "            target[key] += to_update[key]\n",
    "    with tf.Session(graph=g, config=tf.ConfigProto(device_count={'GPU': 0})):\n",
    "        for i, base in enumerate(train_data):\n",
    "            image, label, bbox_gt = load_one_example(base, size=(600, 400))\n",
    "            \n",
    "            result_i, _ = inference_one_image(mm, image, label, verbose=(i % 10 == 0), times=3, gt_prob=0.51)\n",
    "            \n",
    "            update_dict(result, result_i)\n",
    "        result.update(my_utils.metric_many_from_counter(result))\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_one_image(net, image, label, bbox_gt=None, verbose=True, times=1, gt_prob=0.8):\n",
    "    if type(image) == str:\n",
    "        image = imread(image)\n",
    "    if verbose:\n",
    "        print('Processing image with shape%s' % (image.shape,))\n",
    "    bbox_pred = net.inference_box(image)\n",
    "    bbox_pred = bbox_xy_to_tlwh(bbox_pred, size=image.shape[:2])\n",
    "\n",
    "    prediction = crf.crf_from_bbox(image, bbox=bbox_pred, gt_prob=gt_prob)\n",
    "    if times > 1:\n",
    "        for i in range(times - 1):\n",
    "            unary = crf.get_unary_term(prediction, unary_from='label', n_classes=2, gt_prob=gt_prob)\n",
    "            prediction = crf.crf_post_process(image, unary)\n",
    "\n",
    "    result = my_utils.count_many(prediction, label)\n",
    "    prediction = {\n",
    "        'label': prediction,\n",
    "        'bbox': bbox_pred,\n",
    "    }\n",
    "    if bbox_gt is not None:\n",
    "        prediction['IoU'] = my_utils.calc_bbox_iou(bbox_pred, bbox_gt)\n",
    "    return result, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_one_example(base, size=None):\n",
    "    image = imread(base + '_orig.jpg')\n",
    "    label = imread(base + '_contour.png')\n",
    "    label[label == 255] = 1\n",
    "    bbox = my_utils.calc_bbox(label)\n",
    "    if size:\n",
    "        image = imresize(image, size=size)\n",
    "        label = imresize(label, size=size, interp='nearest')\n",
    "    return image, label, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_one_result(image, label, label_pred, bbox_gt, bbox_pred):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.subplot(311)\n",
    "    plt.imshow(image)\n",
    "    top, left, height, width = bbox_gt\n",
    "    plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='b'))\n",
    "\n",
    "    top, left, height, width = bbox_pred\n",
    "    plt.gca().add_patch(plt.Rectangle((left, top), width, height, alpha=0.2, color='r'))\n",
    "    \n",
    "    plt.subplot(312)\n",
    "    plt.imshow(label_pred, cmap='gray')\n",
    "    \n",
    "    plt.subplot(313)\n",
    "    plt.imshow(label, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, bbox_gt = load_one_example(test_data[7])\n",
    "result, prediction = inference_one_image(mm, image, label, bbox_gt, times=3, gt_prob=0.51)\n",
    "print(result)\n",
    "label_pred, bbox_pred = prediction['label'], prediction['bbox']\n",
    "show_one_result(image, label, label_pred, bbox_gt, bbox_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
